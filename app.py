import streamlit as st
import os
import tempfile
import json
import base64
from processing.parser import parse_srt, parse_srt_content
from processing.analyzer import analyze_words, apply_styling
from processing.formatter import generate_enhanced_output, json_to_srt
from processing.advanced_tools import analyze_subtitle_statistics, optimize_timing, check_errors, auto_translate
from langdetect import detect
from rich.console import Console
from rich.markdown import Markdown
import pysrt
from webvtt import WebVTT
import emoji
from docx import Document
import io

st.set_page_config(
    page_title="SRT Highlighter Pro - AI Tool",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Add custom CSS
st.markdown("""
<style>
    .stApp {
        max-width: 1200px;
        margin: 0 auto;
    }
    .main-header {
        text-align: center;
        color: #2e7d32;
        margin-bottom: 2rem;
    }
    .feature-card {
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #e0e0e0;
        margin-bottom: 1rem;
    }
    .output-preview {
        background-color: #f5f5f5;
        padding: 1rem;
        border-radius: 5px;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        border-radius: 4px 4px 0px 0px;
        padding: 10px 16px;
        font-weight: 600;
    }
    .feedback-box {
        background-color: #e8f5e9;
        padding: 1rem;
        border-radius: 5px;
        margin-top: 1rem;
    }
    .error-box {
        background-color: #ffebee;
        padding: 1rem;
        border-radius: 5px;
        margin-top: 1rem;
    }
</style>
""", unsafe_allow_html=True)

def detect_language(text):
    """Detect the language of the text"""
    try:
        return detect(text)
    except:
        return 'en'  # Default to English if detection fails

def get_file_extension(output_format):
    """Get the appropriate file extension based on the output format"""
    format_extensions = {
        'html': '.html',
        'html_classic': '.html',
        'enhanced_srt': '.srt',
        'standard_srt': '.srt',
        'vtt': '.vtt',
        'ass': '.ass',
        'docx': '.docx',
        'json': '.json'
    }
    return format_extensions.get(output_format, '.txt')

def get_mime_type(output_format):
    """Get the appropriate MIME type based on the output format"""
    format_mimes = {
        'html': 'text/html',
        'html_classic': 'text/html',
        'enhanced_srt': 'text/plain',
        'standard_srt': 'text/plain',
        'vtt': 'text/vtt',
        'ass': 'text/plain',
        'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
        'json': 'application/json'
    }
    return format_mimes.get(output_format, 'text/plain')

def convert_format(file_content, from_format, to_format):
    """Convert subtitle file from one format to another"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{from_format}') as temp_file:
        temp_file.write(file_content)
        temp_file_path = temp_file.name
    
    output_content = None
    
    try:
        if from_format == 'srt' and to_format == 'vtt':
            # Convert SRT to WebVTT
            srt_data = pysrt.open(temp_file_path)
            vtt = WebVTT()
            
            for sub in srt_data:
                vtt.captions.append(WebVTT().Caption(
                    start=str(sub.start).replace(',', '.'),
                    end=str(sub.end).replace(',', '.'),
                    text=sub.text
                ))
            
            # Save to temporary file
            output_path = temp_file_path.replace('.srt', '.vtt')
            vtt.save(output_path)
            
            with open(output_path, 'r', encoding='utf-8') as f:
                output_content = f.read()
            
            os.unlink(output_path)
        
        elif from_format == 'vtt' and to_format == 'srt':
            # Convert WebVTT to SRT
            vtt = WebVTT().read(temp_file_path)
            srt_content = []
            
            for i, caption in enumerate(vtt.captions, 1):
                srt_content.append(f"{i}\n")
                start = caption.start.replace('.', ',')
                end = caption.end.replace('.', ',')
                srt_content.append(f"{start} --> {end}\n")
                srt_content.append(f"{caption.text}\n\n")
            
            output_content = ''.join(srt_content)
        
        elif from_format == 'srt' and to_format == 'ass':
            # Convert SRT to ASS
            srt_data = pysrt.open(temp_file_path)
            words_data = []
            
            for sub in srt_data:
                words_data.append({
                    'word': sub.text,
                    'start_time': str(sub.start),
                    'end_time': str(sub.end)
                })
            
            output_content = generate_enhanced_output(words_data, output_format='ass')
        
        elif from_format == 'json' and to_format == 'srt':
            # Convert JSON to SRT
            with open(temp_file_path, 'r', encoding='utf-8') as f:
                json_data = json.load(f)
            output_content = json_to_srt(json_data)
        
        elif from_format == 'srt' and to_format == 'docx':
            # Convert SRT to DOCX
            srt_data = pysrt.open(temp_file_path)
            doc = Document()
            
            for sub in srt_data:
                p = doc.add_paragraph()
                p.add_run(f"[{sub.start} --> {sub.end}]\n").italic = True
                p.add_run(sub.text)
                doc.add_paragraph()  # Add blank line
            
            # Save to temporary file
            output_path = temp_file_path.replace('.srt', '.docx')
            doc.save(output_path)
            
            # Read the file as bytes for download
            with open(output_path, 'rb') as f:
                output_content = f.read()
            
            os.unlink(output_path)
        
        # Clean up temporary file
        os.unlink(temp_file_path)
        
        return output_content
    except Exception as e:
        # Clean up and re-raise
        try:
            os.unlink(temp_file_path)
        except:
            pass
        raise e

def process_subtitle_analysis(words_data, language_code, min_importance, use_emojis, style_params):
    """Process subtitles with the analyzer"""
    if not words_data:
        return None, None
    
    # Process the words with the analyzer
    analyzed_words = analyze_words(words_data, language=language_code, min_importance=min_importance, use_emojis=use_emojis)
    
    # Apply styling
    styled_words = apply_styling(analyzed_words, use_emojis=use_emojis, **style_params)
    
    return analyzed_words, styled_words

def main():
    st.markdown("<h1 class='main-header'>üéØ AI SRT Highlighter Pro</h1>", unsafe_allow_html=True)
    
    # Create tabs for different functions
    tab1, tab2, tab3 = st.tabs(["L√†m n·ªïi b·∫≠t ph·ª• ƒë·ªÅ", "Chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng", "C√¥ng c·ª• n√¢ng cao"])
    
    with tab1:
        st.markdown("""
        <div class='feature-card'>
        üí° C√¥ng c·ª• t·ª± ƒë·ªông l√†m n·ªïi b·∫≠t c√°c t·ª´ quan tr·ªçng trong file ph·ª• ƒë·ªÅ v√† th√™m bi·ªÉu t∆∞·ª£ng ph√π h·ª£p.
        H·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng v√† t√≠nh nƒÉng n√¢ng cao.
        </div>
        """, unsafe_allow_html=True)
        
        # Enhanced sidebar configuration
        with st.sidebar:
            st.header("‚öôÔ∏è C·∫•u h√¨nh n√¢ng cao")
            
            # Language settings
            st.subheader("Ng√¥n ng·ªØ")
            auto_detect = st.checkbox("T·ª± ƒë·ªông ph√°t hi·ªán ng√¥n ng·ªØ", value=True)
            if not auto_detect:
                language = st.selectbox(
                    "Ng√¥n ng·ªØ ph√¢n t√≠ch",
                    ["Ti·∫øng Anh", "Ti·∫øng Vi·ªát", "Ti·∫øng Trung", "Ti·∫øng Nh·∫≠t", "Ti·∫øng H√†n"],
                    index=0
                )
                language_code_map = {
                    "Ti·∫øng Anh": "en", 
                    "Ti·∫øng Vi·ªát": "vi", 
                    "Ti·∫øng Trung": "zh", 
                    "Ti·∫øng Nh·∫≠t": "ja", 
                    "Ti·∫øng H√†n": "ko"
                }
                lang_code = language_code_map.get(language, "en")
            else:
                lang_code = None  # Will be detected automatically
            
            # Output format settings
            st.subheader("ƒê·ªãnh d·∫°ng ƒë·∫ßu ra")
            output_format = st.selectbox(
                "Ch·ªçn ƒë·ªãnh d·∫°ng",
                [
                    "HTML (Modern)", 
                    "HTML (Classic)", 
                    "SRT N√¢ng cao",
                    "SRT Ti√™u chu·∫©n",
                    "WebVTT",
                    "ASS/SSA",
                    "DOCX",
                    "JSON"
                ],
                index=0
            )
            
            # Style settings
            st.subheader("T√πy ch·ªânh ki·ªÉu d√°ng")
            use_custom_colors = st.checkbox("S·ª≠ d·ª•ng m√†u t√πy ch·ªânh", value=False)
            if use_custom_colors:
                primary_color = st.color_picker("M√†u ch√≠nh", "#FF4B4B")
                secondary_color = st.color_picker("M√†u ph·ª•", "#45C6FF")
            else:
                primary_color = "#FF9900"
                secondary_color = "#3357FF"
            
            # Advanced settings
            st.subheader("C√†i ƒë·∫∑t n√¢ng cao")
            group_words = st.checkbox("Nh√≥m t·ª´ theo th·ªùi gian", value=True)
            min_word_importance = st.slider(
                "Ng∆∞·ª°ng t·ª´ quan tr·ªçng",
                min_value=0.0,
                max_value=1.0,
                value=0.5,
                step=0.1
            )
            use_emojis = st.checkbox("Th√™m bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c", value=True)
            
        # Main content area
        st.header("1. T·∫£i l√™n file ph·ª• ƒë·ªÅ")
        
        upload_option = st.radio(
            "Ch·ªçn c√°ch nh·∫≠p d·ªØ li·ªáu",
            ["T·∫£i l√™n file", "Nh·∫≠p n·ªôi dung tr·ª±c ti·∫øp", "T·ª´ URL"]
        )
        
        words_data = None
        
        if upload_option == "T·∫£i l√™n file":
            uploaded_file = st.file_uploader("T·∫£i l√™n file SRT", type=["srt", "vtt", "json"], key="upload_srt")
            
            if uploaded_file is not None:
                # Save file temporarily
                with tempfile.NamedTemporaryFile(delete=False, suffix=f'.{uploaded_file.name.split(".")[-1]}') as temp_file:
                    temp_file.write(uploaded_file.getbuffer())
                    temp_file_path = temp_file.name
                    
                # Process file
                try:
                    file_extension = uploaded_file.name.split(".")[-1].lower()
                    
                    if file_extension == "srt":
                        words_data = parse_srt(temp_file_path)
                    elif file_extension == "vtt":
                        # Convert VTT to SRT first
                        vtt = WebVTT().read(temp_file_path)
                        srt_path = temp_file_path.replace(".vtt", ".srt")
                        
                        with open(srt_path, 'w', encoding='utf-8') as f:
                            for i, caption in enumerate(vtt.captions, 1):
                                f.write(f"{i}\n")
                                start = caption.start.replace('.', ',')
                                end = caption.end.replace('.', ',')
                                f.write(f"{start} --> {end}\n")
                                f.write(f"{caption.text}\n\n")
                        
                        words_data = parse_srt(srt_path)
                        os.unlink(srt_path)
                    elif file_extension == "json":
                        with open(temp_file_path, 'r', encoding='utf-8') as f:
                            json_data = json.load(f)
                            words_data = json_data  # Assuming JSON is already in the correct format
                    
                    st.success(f"ƒê√£ t·∫£i file th√†nh c√¥ng! T√¨m th·∫•y {len(words_data)} t·ª´/ph√¢n ƒëo·∫°n.")
                    
                    # Show preview
                    if words_data:
                        with st.expander("Xem tr∆∞·ªõc d·ªØ li·ªáu th√¥", expanded=False):
                            st.write(words_data[:10])
                    
                    # Clean up temp file
                    try:
                        os.unlink(temp_file_path)
                    except:
                        pass
                except Exception as e:
                    st.error(f"L·ªói khi x·ª≠ l√Ω file: {e}")
                    # Clean up temp file if there's an error
                    try:
                        os.unlink(temp_file_path)
                    except:
                        pass
        
        elif upload_option == "Nh·∫≠p n·ªôi dung tr·ª±c ti·∫øp":
            # Direct SRT content input
            srt_content = st.text_area("Nh·∫≠p n·ªôi dung file SRT:", height=300)
            
            if st.button("X·ª≠ l√Ω n·ªôi dung", key="process_srt_content") and srt_content:
                try:
                    words_data = parse_srt_content(srt_content)
                    st.success(f"ƒê√£ x·ª≠ l√Ω n·ªôi dung th√†nh c√¥ng! T√¨m th·∫•y {len(words_data)} t·ª´/ph√¢n ƒëo·∫°n.")
                    
                    # Show preview
                    if words_data:
                        with st.expander("Xem tr∆∞·ªõc d·ªØ li·ªáu th√¥", expanded=False):
                            st.write(words_data[:10])
                except Exception as e:
                    st.error(f"L·ªói khi x·ª≠ l√Ω n·ªôi dung: {e}")
        
        else:
            # URL option
            url = st.text_input("Nh·∫≠p URL c·ªßa file SRT")
            
            if st.button("T·∫£i l√™n t·ª´ URL", key="process_url") and url:
                try:
                    import requests
                    response = requests.get(url)
                    
                    if response.status_code == 200:
                        content = response.text
                        # Save to temp file
                        with tempfile.NamedTemporaryFile(delete=False, suffix='.srt') as temp_file:
                            temp_file.write(content.encode('utf-8'))
                            temp_file_path = temp_file.name
                        
                        words_data = parse_srt(temp_file_path)
                        st.success(f"ƒê√£ t·∫£i file t·ª´ URL th√†nh c√¥ng! T√¨m th·∫•y {len(words_data)} t·ª´/ph√¢n ƒëo·∫°n.")
                        
                        # Show preview
                        if words_data:
                            with st.expander("Xem tr∆∞·ªõc d·ªØ li·ªáu th√¥", expanded=False):
                                st.write(words_data[:10])
                        
                        # Clean up temp file
                        try:
                            os.unlink(temp_file_path)
                        except:
                            pass
                    else:
                        st.error(f"Kh√¥ng th·ªÉ t·∫£i file t·ª´ URL: HTTP {response.status_code}")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i l√™n t·ª´ URL: {e}")
        
        # New features for subtitle processing
        if words_data:
            st.header("2. X·ª≠ l√Ω v√† ph√¢n t√≠ch")
            
            with st.spinner("ƒêang x·ª≠ l√Ω..."):
                try:
                    # Auto-detect language if enabled
                    if auto_detect and words_data:
                        # Get sample text for language detection
                        sample_text = " ".join([word.get('word', '') for word in words_data[:50]])
                        lang_code = detect_language(sample_text)
                        st.info(f"ƒê√£ ph√°t hi·ªán ng√¥n ng·ªØ: {lang_code}")
                    
                    # Prepare style parameters
                    style_params = {}
                    if use_custom_colors:
                        style_params['primary_color'] = primary_color
                        style_params['secondary_color'] = secondary_color
                    
                    # Process and analyze the subtitles
                    analyzed_words, styled_words = process_subtitle_analysis(
                        words_data, 
                        lang_code, 
                        min_word_importance, 
                        use_emojis, 
                        style_params
                    )
                    
                    # Map output format selection to actual format string
                    format_mapping = {
                        "HTML (Modern)": "html",
                        "HTML (Classic)": "html_classic",
                        "SRT N√¢ng cao": "enhanced_srt",
                        "SRT Ti√™u chu·∫©n": "standard_srt",
                        "WebVTT": "vtt",
                        "ASS/SSA": "ass",
                        "DOCX": "docx",
                        "JSON": "json"
                    }
                    
                    output_format_str = format_mapping.get(output_format, "html")
                    
                    if styled_words:
                        # Generate output based on format
                        enhanced_output = generate_enhanced_output(
                            styled_words, 
                            output_format=output_format_str, 
                            group_words=group_words, 
                            style_params=style_params if use_custom_colors else None
                        )
                        
                        if enhanced_output:
                            st.success("ƒê√£ x·ª≠ l√Ω v√† ƒë·ªãnh d·∫°ng th√†nh c√¥ng!")
                            
                            # Special handling for DOCX
                            if output_format_str == "docx":
                                # Create a BytesIO object for DOCX
                                output_bytes = io.BytesIO()
                                doc = Document()
                                
                                for word in styled_words:
                                    p = doc.add_paragraph()
                                    p.add_run(f"[{word.get('start_time', '')} --> {word.get('end_time', '')}]\n").italic = True
                                    
                                    # Add styling based on importance
                                    if word.get('important', False):
                                        run = p.add_run(f"{word.get('primary_icon', '')} {word.get('word', '')}")
                                        run.bold = True
                                        # Convert hex color to RGB for docx
                                        color = word.get('style', {}).get('color', '#000000')
                                        if color.startswith('#'):
                                            r = int(color[1:3], 16)
                                            g = int(color[3:5], 16)
                                            b = int(color[5:7], 16)
                                            run.font.color.rgb = (r, g, b)
                                    else:
                                        p.add_run(f"{word.get('primary_icon', '')} {word.get('word', '')}")
                                    
                                    doc.add_paragraph()  # Add blank line
                                
                                doc.save(output_bytes)
                                output_bytes.seek(0)
                                
                                st.download_button(
                                    "T·∫£i xu·ªëng k·∫øt qu·∫£ DOCX",
                                    output_bytes,
                                    file_name=f"enhanced_subtitles.docx",
                                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                                )
                            else:
                                st.download_button(
                                    "T·∫£i xu·ªëng k·∫øt qu·∫£",
                                    enhanced_output,
                                    file_name=f"enhanced_subtitles{get_file_extension(output_format_str)}",
                                    mime=get_mime_type(output_format_str)
                                )
                            
                            # Preview the output
                            with st.expander("Xem tr∆∞·ªõc k·∫øt qu·∫£", expanded=True):
                                if output_format_str == "html":
                                    st.markdown(enhanced_output, unsafe_allow_html=True)
                                elif output_format_str == "docx":
                                    st.info("T·∫≠p tin DOCX kh√¥ng th·ªÉ xem tr∆∞·ªõc tr·ª±c ti·∫øp. Vui l√≤ng t·∫£i xu·ªëng ƒë·ªÉ xem.")
                                else:
                                    st.code(enhanced_output)
                                    
                            # Show statistics
                            with st.expander("Th·ªëng k√™ ph√¢n t√≠ch", expanded=False):
                                total_words = len(styled_words)
                                important_words = sum(1 for word in styled_words if word.get('important', False))
                                
                                st.write(f"T·ªïng s·ªë t·ª´: {total_words}")
                                st.write(f"S·ªë t·ª´ quan tr·ªçng: {important_words} ({important_words/total_words*100:.1f}%)")
                                
                                # Category distribution
                                categories = {}
                                for word in styled_words:
                                    for cat in word.get('categories', []):
                                        categories[cat] = categories.get(cat, 0) + 1
                                
                                if categories:
                                    st.write("Ph√¢n b·ªë theo danh m·ª•c:")
                                    for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
                                        st.write(f"- {cat}: {count} t·ª´ ({count/total_words*100:.1f}%)")
                        else:
                            st.warning("Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·∫ßu ra ƒë∆∞·ª£c t·∫°o.")
                    else:
                        st.warning("Kh√¥ng th·ªÉ ph√¢n t√≠ch n·ªôi dung. Vui l√≤ng ki·ªÉm tra l·∫°i d·ªØ li·ªáu ƒë·∫ßu v√†o.")
                except Exception as e:
                    st.error(f"L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {str(e)}")
                    st.error("Vui l√≤ng ki·ªÉm tra l·∫°i d·ªØ li·ªáu ƒë·∫ßu v√†o v√† th·ª≠ l·∫°i.")

    with tab2:
        st.header("üîÑ Chuy·ªÉn ƒë·ªïi ƒë·ªãnh d·∫°ng ph·ª• ƒë·ªÅ")
        
        # Define conversion options
        conversion_options = {
            "SRT ‚ü∂ WebVTT": {"from": "srt", "to": "vtt"},
            "WebVTT ‚ü∂ SRT": {"from": "vtt", "to": "srt"},
            "SRT ‚ü∂ ASS": {"from": "srt", "to": "ass"},
            "JSON ‚ü∂ SRT": {"from": "json", "to": "srt"},
            "SRT ‚ü∂ DOCX": {"from": "srt", "to": "docx"}
        }
        
        selected_conversion = st.selectbox(
            "Ch·ªçn ki·ªÉu chuy·ªÉn ƒë·ªïi",
            list(conversion_options.keys())
        )
        
        conversion_info = conversion_options[selected_conversion]
        
        # File upload for conversion
        uploaded_file = st.file_uploader(
            f"T·∫£i l√™n file {conversion_info['from'].upper()}", 
            type=[conversion_info['from']], 
            key="convert_upload"
        )
        
        if uploaded_file is not None:
            try:
                # Process the uploaded file
                file_content = uploaded_file.getbuffer()
                
                output_content = convert_format(
                    file_content, 
                    conversion_info['from'], 
                    conversion_info['to']
                )
                
                if output_content:
                    # Determine download button parameters
                    file_extension = f".{conversion_info['to']}"
                    mime_type = get_mime_type(conversion_info['to'])
                    
                    # Create download button
                    st.download_button(
                        f"T·∫£i xu·ªëng file {conversion_info['to'].upper()}",
                        output_content,
                        file_name=f"converted{file_extension}",
                        mime=mime_type
                    )
                    
                    # Preview content if not binary
                    if conversion_info['to'] != "docx":
                        with st.expander("Xem tr∆∞·ªõc n·ªôi dung", expanded=False):
                            st.code(output_content)
                    else:
                        st.info("T·∫≠p tin DOCX kh√¥ng th·ªÉ xem tr∆∞·ªõc tr·ª±c ti·∫øp. Vui l√≤ng t·∫£i xu·ªëng ƒë·ªÉ xem.")
                
            except Exception as e:
                st.error(f"L·ªói khi chuy·ªÉn ƒë·ªïi file: {str(e)}")
                st.error("Vui l√≤ng ki·ªÉm tra l·∫°i ƒë·ªãnh d·∫°ng file ƒë·∫ßu v√†o.")

    with tab3:
        st.header("üõ†Ô∏è C√¥ng c·ª• n√¢ng cao")
        
        tool_options = {
            "Ph√¢n t√≠ch th·ªëng k√™ ph·ª• ƒë·ªÅ": "subtitle_stats",
            "T·ªëi ∆∞u h√≥a th·ªùi gian": "timing_optimization",
            "Ki·ªÉm tra l·ªói": "error_check",
            "D·ªãch t·ª± ƒë·ªông": "auto_translate"
        }
        
        selected_tool = st.selectbox(
            "Ch·ªçn c√¥ng c·ª•",
            list(tool_options.keys())
        )
        
        tool_type = tool_options[selected_tool]
        
        # File upload for advanced tools
        uploaded_file = st.file_uploader(
            "T·∫£i l√™n file SRT", 
            type=["srt"], 
            key="advanced_tools_upload"
        )
        
        if uploaded_file is not None:
            try:
                # Save file temporarily
                with tempfile.NamedTemporaryFile(delete=False, suffix='.srt') as temp_file:
                    temp_file.write(uploaded_file.getbuffer())
                    temp_file_path = temp_file.name
                
                # Load SRT data
                srt_data = pysrt.open(temp_file_path)
                
                if tool_type == "subtitle_stats":
                    # Analyze subtitle statistics
                    stats = analyze_subtitle_statistics(srt_data)
                    
                    st.subheader("Th·ªëng k√™ ph·ª• ƒë·ªÅ")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.metric("T·ªïng s·ªë ph·ª• ƒë·ªÅ", len(srt_data))
                        st.metric("T·ªïng s·ªë t·ª´", stats['word_count'])
                        st.metric("S·ªë t·ª´ kh√°c nhau", len(stats['unique_words']))
                    
                    with col2:
                        total_seconds = stats['total_duration'].total_seconds()
                        st.metric("T·ªïng th·ªùi l∆∞·ª£ng", f"{int(total_seconds // 60)} ph√∫t {int(total_seconds % 60)} gi√¢y")
                        avg_words = stats['avg_words_per_subtitle']
                        st.metric("Trung b√¨nh t·ª´/ph·ª• ƒë·ªÅ", f"{avg_words:.1f}")
                        avg_duration = stats['avg_duration_per_subtitle'].total_seconds()
                        st.metric("Th·ªùi l∆∞·ª£ng TB/ph·ª• ƒë·ªÅ", f"{avg_duration:.1f} gi√¢y")
                    
                    # Word frequency
                    st.subheader("T·ª´ xu·∫•t hi·ªán nhi·ªÅu nh·∫•t")
                    freq_items = sorted(stats['word_frequency'].items(), key=lambda x: x[1], reverse=True)
                    freq_df = {"T·ª´": [], "T·∫ßn su·∫•t": []}
                    
                    for word, freq in freq_items[:20]:
                        freq_df["T·ª´"].append(word)
                        freq_df["T·∫ßn su·∫•t"].append(freq)
                    
                    st.bar_chart(freq_df, x="T·ª´")
                    
                    # Language distribution if available
                    if stats['language_distribution']:
                        st.subheader("Ph√¢n b·ªë ng√¥n ng·ªØ")
                        langs = {"Ng√¥n ng·ªØ": [], "S·ªë l∆∞·ª£ng": []}
                        
                        for lang, count in stats['language_distribution'].items():
                            langs["Ng√¥n ng·ªØ"].append(lang)
                            langs["S·ªë l∆∞·ª£ng"].append(count)
                        
                        st.bar_chart(langs, x="Ng√¥n ng·ªØ")
                
                elif tool_type == "timing_optimization":
                    # UI controls for optimization parameters
                    st.subheader("T√πy ch·ªçn t·ªëi ∆∞u h√≥a th·ªùi gian")
                    
                    min_duration = st.slider("Th·ªùi l∆∞·ª£ng t·ªëi thi·ªÉu (gi√¢y)", 0.5, 3.0, 1.0, 0.1)
                    max_duration = st.slider("Th·ªùi l∆∞·ª£ng t·ªëi ƒëa (gi√¢y)", 3.0, 10.0, 7.0, 0.1)
                    min_gap = st.slider("Kho·∫£ng c√°ch t·ªëi thi·ªÉu (gi√¢y)", 0.0, 1.0, 0.1, 0.05)
                    
                    if st.button("T·ªëi ∆∞u h√≥a"):
                        with st.spinner("ƒêang t·ªëi ∆∞u h√≥a..."):
                            # Optimize timing
                            optimized_srt = optimize_timing(srt_data, min_duration, max_duration, min_gap)
                            
                            # Save optimized SRT to a temporary file
                            optimized_path = temp_file_path.replace('.srt', '_optimized.srt')
                            optimized_srt_file = pysrt.SubRipFile(optimized_srt)
                            optimized_srt_file.save(optimized_path, encoding='utf-8')
                            
                            # Read the optimized file content
                            with open(optimized_path, 'r', encoding='utf-8') as f:
                                optimized_content = f.read()
                            
                            # Create download button
                            st.download_button(
                                "T·∫£i xu·ªëng SRT ƒë√£ t·ªëi ∆∞u h√≥a",
                                optimized_content,
                                file_name="optimized_subtitle.srt",
                                mime="text/plain"
                            )
                            
                            # Show preview
                            with st.expander("Xem tr∆∞·ªõc n·ªôi dung ƒë√£ t·ªëi ∆∞u h√≥a", expanded=True):
                                st.code(optimized_content[:1000] + "..." if len(optimized_content) > 1000 else optimized_content)
                            
                            # Clean up temporary file
                            try:
                                os.unlink(optimized_path)
                            except:
                                pass
                            
                            # Show statistics comparison
                            st.subheader("So s√°nh tr∆∞·ªõc v√† sau khi t·ªëi ∆∞u h√≥a")
                            
                            # Original stats
                            original_durations = [(sub.end - sub.start).total_seconds() for sub in srt_data]
                            original_avg_duration = sum(original_durations) / len(original_durations) if original_durations else 0
                            
                            # Optimized stats
                            optimized_durations = [(sub.end - sub.start).total_seconds() for sub in optimized_srt]
                            optimized_avg_duration = sum(optimized_durations) / len(optimized_durations) if optimized_durations else 0
                            
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.metric("Th·ªùi l∆∞·ª£ng TB (ban ƒë·∫ßu)", f"{original_avg_duration:.2f}s")
                                st.metric("Th·ªùi l∆∞·ª£ng t·ªëi thi·ªÉu (ban ƒë·∫ßu)", f"{min(original_durations):.2f}s")
                                st.metric("Th·ªùi l∆∞·ª£ng t·ªëi ƒëa (ban ƒë·∫ßu)", f"{max(original_durations):.2f}s")
                            
                            with col2:
                                st.metric("Th·ªùi l∆∞·ª£ng TB (sau t·ªëi ∆∞u)", f"{optimized_avg_duration:.2f}s")
                                st.metric("Th·ªùi l∆∞·ª£ng t·ªëi thi·ªÉu (sau t·ªëi ∆∞u)", f"{min(optimized_durations):.2f}s")
                                st.metric("Th·ªùi l∆∞·ª£ng t·ªëi ƒëa (sau t·ªëi ∆∞u)", f"{max(optimized_durations):.2f}s")
                
                elif tool_type == "error_check":
                    st.subheader("Ki·ªÉm tra l·ªói ph·ª• ƒë·ªÅ")
                    
                    with st.spinner("ƒêang ki·ªÉm tra l·ªói..."):
                        # Check for errors
                        errors = check_errors(srt_data)
                        
                        if errors:
                            st.error(f"ƒê√£ t√¨m th·∫•y {len(errors)} l·ªói trong file ph·ª• ƒë·ªÅ!")
                            
                            for i, error in enumerate(errors, 1):
                                with st.expander(f"L·ªói #{i}: {error['message']}"):
                                    st.write(f"Ph·ª• ƒë·ªÅ th·ª©: {error['subtitle_index']}")
                                    st.write(f"Lo·∫°i l·ªói: {error['type']}")
                                    
                                    # Show the problematic subtitle
                                    subtitle = srt_data[error['subtitle_index'] - 1]
                                    st.code(f"{subtitle.index}\n{subtitle.start} --> {subtitle.end}\n{subtitle.text}")
                            
                            # Offer auto-fix option
                            if st.button("S·ª≠a l·ªói t·ª± ƒë·ªông"):
                                fixed_srt = srt_data.copy()
                                
                                # Fix each error
                                for error in errors:
                                    idx = error['subtitle_index'] - 1
                                    subtitle = fixed_srt[idx]
                                    
                                    if error['type'] == 'negative_duration':
                                        # Fix negative duration by setting end time to start time + 2 seconds
                                        subtitle.end = subtitle.start + pysrt.SubRipTime(0, 0, 2)
                                    
                                    elif error['type'] == 'overlap':
                                        if idx < len(fixed_srt) - 1:
                                            next_subtitle = fixed_srt[idx + 1]
                                            # Fix overlap by adjusting end time
                                            subtitle.end = next_subtitle.start - pysrt.SubRipTime(0, 0, 0, 100)
                                    
                                    elif error['type'] == 'empty_text':
                                        # Fix empty text by adding placeholder
                                        subtitle.text = "[NO TEXT]"
                                    
                                    elif error['type'] == 'too_long':
                                        # No automatic fix for too long subtitles, just highlight
                                        pass
                                
                                # Save fixed SRT to a temporary file
                                fixed_path = temp_file_path.replace('.srt', '_fixed.srt')
                                fixed_srt.save(fixed_path, encoding='utf-8')
                                
                                # Read the fixed file content
                                with open(fixed_path, 'r', encoding='utf-8') as f:
                                    fixed_content = f.read()
                                
                                # Create download button
                                st.download_button(
                                    "T·∫£i xu·ªëng SRT ƒë√£ s·ª≠a l·ªói",
                                    fixed_content,
                                    file_name="fixed_subtitle.srt",
                                    mime="text/plain"
                                )
                                
                                # Clean up temporary file
                                try:
                                    os.unlink(fixed_path)
                                except:
                                    pass
                        else:
                            st.success("Kh√¥ng t√¨m th·∫•y l·ªói n√†o trong file ph·ª• ƒë·ªÅ!")
                
                elif tool_type == "auto_translate":
                    st.subheader("D·ªãch t·ª± ƒë·ªông ph·ª• ƒë·ªÅ")
                    
                    # Select source and target languages
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        source_lang = st.selectbox(
                            "Ng√¥n ng·ªØ ngu·ªìn",
                            ["T·ª± ƒë·ªông ph√°t hi·ªán", "Ti·∫øng Anh", "Ti·∫øng Vi·ªát", "Ti·∫øng Trung", "Ti·∫øng Nh·∫≠t", "Ti·∫øng H√†n", "Ti·∫øng Ph√°p", "Ti·∫øng ƒê·ª©c", "Ti·∫øng T√¢y Ban Nha"],
                            index=0
                        )
                    
                    with col2:
                        target_lang = st.selectbox(
                            "Ng√¥n ng·ªØ ƒë√≠ch",
                            ["Ti·∫øng Anh", "Ti·∫øng Vi·ªát", "Ti·∫øng Trung", "Ti·∫øng Nh·∫≠t", "Ti·∫øng H√†n", "Ti·∫øng Ph√°p", "Ti·∫øng ƒê·ª©c", "Ti·∫øng T√¢y Ban Nha"],
                            index=0
                        )
                    
                    language_code_map = {
                        "T·ª± ƒë·ªông ph√°t hi·ªán": "auto",
                        "Ti·∫øng Anh": "en", 
                        "Ti·∫øng Vi·ªát": "vi", 
                        "Ti·∫øng Trung": "zh", 
                        "Ti·∫øng Nh·∫≠t": "ja", 
                        "Ti·∫øng H√†n": "ko",
                        "Ti·∫øng Ph√°p": "fr",
                        "Ti·∫øng ƒê·ª©c": "de",
                        "Ti·∫øng T√¢y Ban Nha": "es"
                    }
                    
                    source_code = language_code_map.get(source_lang, "auto")
                    target_code = language_code_map.get(target_lang, "en")
                    
                    # Display warning about translation API requirements
                    st.warning("""
                    T√≠nh nƒÉng n√†y y√™u c·∫ßu c√†i ƒë·∫∑t th∆∞ vi·ªán transformers v√† m√¥ h√¨nh d·ªãch thu·∫≠t.
                    N·∫øu b·∫°n ƒëang ch·∫°y ·ª©ng d·ª•ng c·ª•c b·ªô, h√£y ƒë·∫£m b·∫£o b·∫°n ƒë√£ c√†i ƒë·∫∑t:
                    ```
                    pip install transformers sentencepiece
                    ```
                    """)
                    
                    # Check if translation is feasible
                    if source_code == target_code:
                        st.error("Ng√¥n ng·ªØ ngu·ªìn v√† ƒë√≠ch kh√¥ng th·ªÉ gi·ªëng nhau!")
                    else:
                        if st.button("B·∫Øt ƒë·∫ßu d·ªãch"):
                            try:
                                with st.spinner(f"ƒêang d·ªãch t·ª´ {source_lang} sang {target_lang}..."):
                                    # If using auto-detect, detect the language first
                                    if source_code == "auto":
                                        sample_text = "\n".join([sub.text for sub in srt_data[:5]])
                                        detected_lang = detect_language(sample_text)
                                        source_code = detected_lang
                                        st.info(f"ƒê√£ ph√°t hi·ªán ng√¥n ng·ªØ ngu·ªìn: {detected_lang}")
                                    
                                    # Show demo translation for first few subtitles
                                    st.subheader("Xem tr∆∞·ªõc b·∫£n d·ªãch")
                                    
                                    # Create a placeholder for samples
                                    sample_container = st.container()
                                    
                                    with sample_container:
                                        st.write("ƒêang t·∫°o b·∫£n d·ªãch m·∫´u...")
                                    
                                    # In a real implementation, you would use a translation service here
                                    sample_translations = [
                                        {"original": sub.text, "translated": f"[B·∫£n d·ªãch {target_code}] {sub.text}"} 
                                        for sub in srt_data[:5]
                                    ]
                                    
                                    # Update the sample container
                                    with sample_container:
                                        st.write("M·∫´u b·∫£n d·ªãch (5 ph·ª• ƒë·ªÅ ƒë·∫ßu ti√™n):")
                                        for sample in sample_translations:
                                            st.write("---")
                                            st.write(f"**G·ªëc:** {sample['original']}")
                                            st.write(f"**D·ªãch:** {sample['translated']}")
                                    
                                    # In a real implementation, you would translate all subtitles here
                                    # translated_srt = auto_translate(srt_data, source_code, target_code)
                                    
                                    # For demonstration, create a mock translated SRT file
                                    translated_srt = srt_data.copy()
                                    for sub in translated_srt:
                                        sub.text = f"[{target_code}] {sub.text}"
                                    
                                    # Save translated SRT to a temporary file
                                    translated_path = temp_file_path.replace('.srt', f'_{target_code}.srt')
                                    translated_srt.save(translated_path, encoding='utf-8')
                                    
                                    # Read the translated file content
                                    with open(translated_path, 'r', encoding='utf-8') as f:
                                        translated_content = f.read()
                                    
                                    # Create download button
                                    st.download_button(
                                        f"T·∫£i xu·ªëng b·∫£n d·ªãch sang {target_lang}",
                                        translated_content,
                                        file_name=f"translated_{target_code}_subtitle.srt",
                                        mime="text/plain"
                                    )
                                    
                                    # Clean up temporary file
                                    try:
                                        os.unlink(translated_path)
                                    except:
                                        pass
                                    
                                    st.success("ƒê√£ ho√†n th√†nh d·ªãch thu·∫≠t!")
                            except Exception as e:
                                st.error(f"L·ªói khi d·ªãch ph·ª• ƒë·ªÅ: {str(e)}")
                                st.info("ƒê·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng n√†y, b·∫°n c·∫ßn c√†i ƒë·∫∑t th∆∞ vi·ªán transformers v√† c√°c m√¥ h√¨nh d·ªãch thu·∫≠t ph√π h·ª£p.")
                
                # Clean up temporary file
                try:
                    os.unlink(temp_file_path)
                except:
                    pass
            
            except Exception as e:
                st.error(f"L·ªói khi x·ª≠ l√Ω c√¥ng c·ª• n√¢ng cao: {str(e)}")
                # Clean up temporary file if there's an error
                try:
                    os.unlink(temp_file_path)
                except:
                    pass
        
        # Additional info about advanced tools
        st.markdown("""
        ### Th√¥ng tin v·ªÅ c√°c c√¥ng c·ª• n√¢ng cao

        **Ph√¢n t√≠ch th·ªëng k√™ ph·ª• ƒë·ªÅ**: Ph√¢n t√≠ch chi ti·∫øt c√°c th√¥ng s·ªë c·ªßa file ph·ª• ƒë·ªÅ nh∆∞ s·ªë l∆∞·ª£ng t·ª´, th·ªùi l∆∞·ª£ng, t·∫ßn su·∫•t t·ª´.

        **T·ªëi ∆∞u h√≥a th·ªùi gian**: ƒêi·ªÅu ch·ªânh th·ªùi gian hi·ªÉn th·ªã c·ªßa ph·ª• ƒë·ªÅ ƒë·ªÉ c·∫£i thi·ªán tr·∫£i nghi·ªám ng∆∞·ªùi xem.

        **Ki·ªÉm tra l·ªói**: Ph√°t hi·ªán v√† s·ª≠a c√°c l·ªói ph·ªï bi·∫øn trong file ph·ª• ƒë·ªÅ nh∆∞ th·ªùi gian √¢m, tr√πng l·∫∑p, vƒÉn b·∫£n tr·ªëng.

        **D·ªãch t·ª± ƒë·ªông**: D·ªãch ph·ª• ƒë·ªÅ sang ng√¥n ng·ªØ kh√°c s·ª≠ d·ª•ng c√°c m√¥ h√¨nh h·ªçc m√°y.
        """)

if __name__ == "__main__":
    main()